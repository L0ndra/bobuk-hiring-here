# Senior Data Engineer

**Location:** Remote  
**Job Type:** Full-Time  
**Contact:** Illia Lubenets (@L0ndra on TG)  
**Salary Range:** $4000â€“$8000  

---

## About Us  

We are a specialized design bureau in the private equity sector, focused on driving innovation and development across a diverse portfolio of companies owned by our group of investors. Our team delivers value through three core pillars:  

1. **Long-term Project Development:** We execute and support extensive projects in both physical and digital realms, ranging from ski resorts and clinics to enterprise-level CRM systems.  
2. **Research and Rapid Prototyping:** We explore cutting-edge technologies, providing proof-of-concept solutions to accelerate innovation in AI applications and other emerging fields.  
3. **Secure Infrastructure Deployment and Maintenance:** Our platform team ensures robust, scalable, and secure infrastructure for ongoing operations across the group's businesses and startups.  

In essence, we are an R&D powerhouse supporting the technological and operational growth of companies within our investors' portfolio, bridging vision and execution for transformative outcomes.  

---

## Role Overview  

We are seeking a **Senior Data Engineer** to join our Platform team. You will be responsible for ensuring that all data pipelines run smoothly across our businesses and that all data warehouses are safe, secure, and optimized, so analytics and business intelligence teams have efficient data access.

---

## Responsibilities  

### Data Infrastructure Management  

- Develop and maintain data models and transformations inside **PostgreSQL** database and **ClickHouse** data warehouse, ensuring scalability, efficient data storage and retrieval to support analytics and reporting.
- Interact with portfolio companies to collect data and organize its transfer to a centralized storage on **Amazon S3**.
- Design, build, and maintain scalable data pipelines using **Airflow** and **dbt**.

### Data Quality and Monitoring  

- Monitor and troubleshoot data workflows, ensuring data integrity and consistency.
- Maintain data quality by implementing necessary automated validation processes.
- Create efficient data processing jobs using **Python**.

### Business Intelligence and Reporting  

- Work closely with analysts, BI developers and business stakeholders to deliver insights through effective reporting systems with data visualizations in **Tableau** and **Superset**.
- Focus on automating processes and minimizing manual intervention, striving to build an effective system with a minimum number of connected human resources.

### Technology Advancement  

- Stay up-to-date with the latest developments in Data Engineering and cloud technologies.

---

## Qualifications  

### Technical Expertise  

- 5+ years of experience as a Data Engineer.
- Strong **SQL** skills and familiarity with data warehousing concepts.
- Strong experience with **PostgreSQL** and **ClickHouse**, including data modeling and complex query execution and optimization.
- Strong experience with **Python** for data processing and automation tasks.
- Strong experience with **Airflow** for orchestrating ETL processes.
- Experience with **dbt** for data quality and transformations.
- Experience working in on-premise environments with an understanding of cloud integration challenges.
- Experience with AWS or Google Cloud, especially with cloud data warehouses.

### Soft Skills  

- Strong problem-solving skills and attention to detail.
- Ability to collaborate with cross-functional teams, including data analysts, engineers, and business stakeholders.

### Preferred Qualifications  

- Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
- Experience working in startups or fast-paced environments.
- Experience working in the iGaming industry ecosystem.
- Experience with **Kafka**, **Flink** or other streaming technologies for design and support real-time data pipelines.
- Experience with BI tools such as **Tableau** and **Superset**.
- Knowledge of analytical patterns and data visualization best practices.
- Knowledge of data governance and security frameworks.
- Knowledge of CI/CD pipelines for data engineering.
